{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the tuned CatBoost model...\n",
      "0:\tlearn: 0.6827533\ttotal: 54ms\tremaining: 16.1s\n",
      "50:\tlearn: 0.4220702\ttotal: 120ms\tremaining: 587ms\n",
      "100:\tlearn: 0.3304941\ttotal: 179ms\tremaining: 353ms\n",
      "150:\tlearn: 0.2741036\ttotal: 255ms\tremaining: 251ms\n",
      "200:\tlearn: 0.2276690\ttotal: 332ms\tremaining: 163ms\n",
      "250:\tlearn: 0.1873314\ttotal: 399ms\tremaining: 77.9ms\n",
      "299:\tlearn: 0.1571405\ttotal: 462ms\tremaining: 0us\n",
      "0:\tlearn: 0.6824584\ttotal: 3.62ms\tremaining: 1.08s\n",
      "50:\tlearn: 0.4019573\ttotal: 82.6ms\tremaining: 403ms\n",
      "100:\tlearn: 0.2962517\ttotal: 212ms\tremaining: 417ms\n",
      "150:\tlearn: 0.2362105\ttotal: 334ms\tremaining: 330ms\n",
      "200:\tlearn: 0.1913557\ttotal: 477ms\tremaining: 235ms\n",
      "250:\tlearn: 0.1495897\ttotal: 620ms\tremaining: 121ms\n",
      "299:\tlearn: 0.1172553\ttotal: 751ms\tremaining: 0us\n",
      "0:\tlearn: 0.6759461\ttotal: 2.97ms\tremaining: 887ms\n",
      "50:\tlearn: 0.3477279\ttotal: 53.3ms\tremaining: 260ms\n",
      "100:\tlearn: 0.2794743\ttotal: 103ms\tremaining: 203ms\n",
      "150:\tlearn: 0.2389112\ttotal: 152ms\tremaining: 150ms\n",
      "200:\tlearn: 0.2097690\ttotal: 206ms\tremaining: 102ms\n",
      "250:\tlearn: 0.1882353\ttotal: 280ms\tremaining: 54.7ms\n",
      "299:\tlearn: 0.1684177\ttotal: 380ms\tremaining: 0us\n",
      "0:\tlearn: 0.6760109\ttotal: 2.62ms\tremaining: 784ms\n",
      "50:\tlearn: 0.3450841\ttotal: 141ms\tremaining: 690ms\n",
      "100:\tlearn: 0.2767224\ttotal: 280ms\tremaining: 551ms\n",
      "150:\tlearn: 0.2403809\ttotal: 394ms\tremaining: 389ms\n",
      "200:\tlearn: 0.2067749\ttotal: 520ms\tremaining: 256ms\n",
      "250:\tlearn: 0.1769246\ttotal: 591ms\tremaining: 115ms\n",
      "299:\tlearn: 0.1564633\ttotal: 644ms\tremaining: 0us\n",
      "0:\tlearn: 0.6765437\ttotal: 1.93ms\tremaining: 576ms\n",
      "50:\tlearn: 0.3236501\ttotal: 130ms\tremaining: 635ms\n",
      "100:\tlearn: 0.2483802\ttotal: 261ms\tremaining: 514ms\n",
      "150:\tlearn: 0.2103362\ttotal: 397ms\tremaining: 391ms\n",
      "200:\tlearn: 0.1806418\ttotal: 515ms\tremaining: 253ms\n",
      "250:\tlearn: 0.1560884\ttotal: 584ms\tremaining: 114ms\n",
      "299:\tlearn: 0.1366078\ttotal: 641ms\tremaining: 0us\n",
      "0:\tlearn: 0.6706751\ttotal: 1.34ms\tremaining: 400ms\n",
      "50:\tlearn: 0.2885263\ttotal: 52.4ms\tremaining: 256ms\n",
      "100:\tlearn: 0.2351351\ttotal: 125ms\tremaining: 245ms\n",
      "150:\tlearn: 0.2058693\ttotal: 257ms\tremaining: 254ms\n",
      "200:\tlearn: 0.1807767\ttotal: 407ms\tremaining: 200ms\n",
      "250:\tlearn: 0.1613101\ttotal: 544ms\tremaining: 106ms\n",
      "299:\tlearn: 0.1521445\ttotal: 650ms\tremaining: 0us\n",
      "Evaluating the model...\n",
      "Test F1 Score: 0.70\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.82      0.58        55\n",
      "           1       0.47      0.79      0.59        48\n",
      "           2       0.59      0.97      0.73        75\n",
      "           3       0.57      0.93      0.71        76\n",
      "           4       0.61      0.92      0.73        73\n",
      "           5       0.64      0.96      0.76        93\n",
      "\n",
      "   micro avg       0.57      0.91      0.70       420\n",
      "   macro avg       0.56      0.90      0.69       420\n",
      "weighted avg       0.57      0.91      0.70       420\n",
      " samples avg       0.50      0.76      0.58       420\n",
      "\n",
      "Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from catboost import CatBoostClassifier\n",
    "import joblib\n",
    "\n",
    "# Function to load data and split into features and target\n",
    "def load_data(file_path, target_columns, selected_features):\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data[selected_features]\n",
    "    y = data[target_columns]\n",
    "    return X, y\n",
    "\n",
    "# Function to initialize a tuned CatBoost classifier within MultiOutputClassifier\n",
    "def initialize_tuned_catboost():\n",
    "    return MultiOutputClassifier(\n",
    "        CatBoostClassifier(\n",
    "            verbose=50,\n",
    "            random_state=42,\n",
    "            early_stopping_rounds=20,\n",
    "            learning_rate=0.025,\n",
    "            depth=7,\n",
    "            iterations=300,\n",
    "            scale_pos_weight=7,\n",
    "            l2_leaf_reg=2\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Main workflow\n",
    "if __name__ == \"__main__\":\n",
    "    # Define file path, features, and target columns\n",
    "    file_path = 'xydata_2021winter.csv'\n",
    "    target_columns_clusters = [f\"Cluster{i}\" for i in range(6)]\n",
    "    selected_features_updated = [\n",
    "        \"Time_Period\", \"Stn Press (kPa)\", \"Dew Point Temp (°C)\", \"Rel Hum (%)\",\n",
    "        \"Visibility (km)\", \"Temp (°C)\", \"Wind Dir (10s deg)\", \"Wind Spd (km/h)\",\n",
    "        \"C0D-1HA\", \"C0D-2HA\", \"C0D-4HA\",  # Cluster 0 historical features\n",
    "        \"C1D-1HA\", \"C1D-2HA\", \"C1D-4HA\",  # Cluster 1 historical features\n",
    "        \"C2D-1HA\", \"C2D-2HA\", \"C2D-3HA\",  # Cluster 2 historical features\n",
    "        \"C3D-1HA\", \"C4D-1HA\", \"C4D-2HA\", \"C5D-1HA\"  # Other cluster features\n",
    "    ]\n",
    "    \n",
    "    # Load and split the data\n",
    "    X, y = load_data(file_path, target_columns_clusters, selected_features_updated)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Initialize and train the model\n",
    "    print(\"Training the tuned CatBoost model...\")\n",
    "    tuned_catboost_model = initialize_tuned_catboost()\n",
    "    tuned_catboost_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    print(\"Evaluating the model...\")\n",
    "    y_test_pred = tuned_catboost_model.predict(X_test)\n",
    "    test_f1_score = f1_score(y_test, y_test_pred, average='weighted')\n",
    "    print(f\"Test F1 Score: {test_f1_score:.2f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_test_pred, zero_division=0))\n",
    "\n",
    "# Save the best estimator from the grid search\n",
    "joblib.dump(tuned_catboost_model, 'catboost_multioutput_model.pkl')\n",
    "print(\"Model saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the trained model...\n",
      "Loading the dataset...\n",
      "Making predictions...\n",
      "Overall Test Set Accuracy Score (Average of All Clusters): 0.63\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          C0       0.50      0.87      0.63       195\n",
      "          C1       0.41      0.70      0.51       155\n",
      "          C2       0.61      0.97      0.75       257\n",
      "          C3       0.60      0.94      0.73       256\n",
      "          C4       0.59      0.93      0.72       244\n",
      "          C5       0.63      0.97      0.76       283\n",
      "\n",
      "   micro avg       0.57      0.92      0.70      1390\n",
      "   macro avg       0.55      0.90      0.68      1390\n",
      "weighted avg       0.57      0.92      0.70      1390\n",
      " samples avg       0.50      0.77      0.57      1390\n",
      "\n",
      "\n",
      "First 5 Predictions vs. True Labels:\n",
      "Row 1\n",
      "--------------------------------------------------\n",
      "C0: Predicted=1, True=1\n",
      "C1: Predicted=0, True=1\n",
      "C2: Predicted=1, True=1\n",
      "C3: Predicted=1, True=0\n",
      "C4: Predicted=1, True=1\n",
      "C5: Predicted=1, True=0\n",
      "\n",
      "--------------------------------------------------\n",
      "Row 2\n",
      "--------------------------------------------------\n",
      "C0: Predicted=1, True=0\n",
      "C1: Predicted=0, True=0\n",
      "C2: Predicted=1, True=1\n",
      "C3: Predicted=1, True=1\n",
      "C4: Predicted=1, True=1\n",
      "C5: Predicted=1, True=1\n",
      "\n",
      "--------------------------------------------------\n",
      "Row 3\n",
      "--------------------------------------------------\n",
      "C0: Predicted=1, True=0\n",
      "C1: Predicted=0, True=0\n",
      "C2: Predicted=1, True=1\n",
      "C3: Predicted=1, True=1\n",
      "C4: Predicted=1, True=1\n",
      "C5: Predicted=1, True=1\n",
      "\n",
      "--------------------------------------------------\n",
      "Row 4\n",
      "--------------------------------------------------\n",
      "C0: Predicted=0, True=0\n",
      "C1: Predicted=0, True=0\n",
      "C2: Predicted=1, True=0\n",
      "C3: Predicted=1, True=0\n",
      "C4: Predicted=0, True=0\n",
      "C5: Predicted=1, True=1\n",
      "\n",
      "--------------------------------------------------\n",
      "Row 5\n",
      "--------------------------------------------------\n",
      "C0: Predicted=1, True=1\n",
      "C1: Predicted=0, True=0\n",
      "C2: Predicted=1, True=0\n",
      "C3: Predicted=1, True=0\n",
      "C4: Predicted=1, True=1\n",
      "C5: Predicted=1, True=1\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Step 1: Load the trained model\n",
    "print(\"Loading the trained model...\")\n",
    "model = joblib.load('catboost_multioutput_model.pkl')\n",
    "\n",
    "# Step 2: Load the new dataset\n",
    "print(\"Loading the dataset...\")\n",
    "data = pd.read_csv('xydata_2023winter.csv')\n",
    "\n",
    "# Step 3: Define the feature and target columns\n",
    "features = [\n",
    "    \"Time_Period\", \"Stn Press (kPa)\", \"Dew Point Temp (°C)\", \"Rel Hum (%)\",\n",
    "    \"Visibility (km)\", \"Temp (°C)\", \"Wind Dir (10s deg)\", \"Wind Spd (km/h)\",\n",
    "    \"C0D-1HA\", \"C0D-2HA\", \"C0D-4HA\",  # Cluster 0 historical features\n",
    "    \"C1D-1HA\", \"C1D-2HA\", \"C1D-4HA\",  # Cluster 1 historical features\n",
    "    \"C2D-1HA\", \"C2D-2HA\", \"C2D-3HA\",  # Cluster 2 historical features\n",
    "    \"C3D-1HA\", \"C4D-1HA\", \"C4D-2HA\", \"C5D-1HA\"  # Other cluster features\n",
    "]\n",
    "\n",
    "target_columns = [f\"Cluster{i}\" for i in range(6)]\n",
    "\n",
    "# Step 4: Ensure all features are present in the dataset\n",
    "for feature in features:\n",
    "    if feature not in data.columns:\n",
    "        data[feature] = 0  # Add missing features with a default value of 0\n",
    "\n",
    "# Step 5: Extract the features (X) and target (y)\n",
    "X = data[features]\n",
    "y_true = data[target_columns]\n",
    "\n",
    "# Step 6: Generate predictions\n",
    "print(\"Making predictions...\")\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# Step 7: Evaluate predictions\n",
    "# Rename clusters for simplicity\n",
    "y_pred_df = pd.DataFrame(y_pred, columns=[f\"C{i}\" for i in range(6)])\n",
    "y_true.columns = [f\"C{i}\" for i in range(6)]\n",
    "\n",
    "# Calculate the accuracy score (mean accuracy across all clusters)\n",
    "cluster_accuracies = []\n",
    "for col in y_pred_df.columns:\n",
    "    cluster_accuracy = accuracy_score(y_true[col], y_pred_df[col])\n",
    "    cluster_accuracies.append(cluster_accuracy)\n",
    "overall_accuracy = sum(cluster_accuracies) / len(cluster_accuracies)\n",
    "\n",
    "print(f\"Overall Test Set Accuracy Score (Average of All Clusters): {overall_accuracy:.2f}\")\n",
    "\n",
    "# Display a detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred_df, target_names=y_pred_df.columns, zero_division=0))\n",
    "\n",
    "# Step 8: Show a comparison of predictions and true labels for the first 5 examples\n",
    "print(\"\\nFirst 5 Predictions vs. True Labels:\")\n",
    "\n",
    "# Concatenate predictions and true values for comparison\n",
    "comparison = pd.concat(\n",
    "    [y_pred_df.head(5), y_true.head(5).reset_index(drop=True)],\n",
    "    axis=1,\n",
    "    keys=[\"Predicted\", \"True\"]\n",
    ")\n",
    "\n",
    "# Format and display predictions and true labels side by side\n",
    "separator = \"\\n\" + \"-\" * 50 + \"\\n\"\n",
    "formatted_output = \"\"\n",
    "\n",
    "for index, row in comparison.iterrows():\n",
    "    formatted_output += f\"Row {index + 1}{separator}\"\n",
    "    for col in y_pred_df.columns:\n",
    "        formatted_output += f\"{col}: Predicted={row[('Predicted', col)]}, True={row[('True', col)]}\\n\"\n",
    "    formatted_output += separator\n",
    "\n",
    "print(formatted_output)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
